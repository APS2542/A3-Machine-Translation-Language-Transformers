# ğŸ§  Thai â†’ English Machine Translation  
### Seq2Seq with Additive Attention (PyTorch + Dash)

This project is part of **NLP Assignment 3 â€“ Make Your Own Machine Translation Language**.  
We implement a **Thai â†’ English Machine Translation system** using a **Seq2Seq model with Additive Attention**, trained in PyTorch and deployed as a web application using **Dash**.

---

## ğŸ“Œ Features

- Seq2Seq Encoderâ€“Decoder architecture (GRU-based)
- Additive (Bahdanau) Attention mechanism
- Thai tokenization using **PyThaiNLP (newmm)**
- Trained model checkpoint for inference
- Interactive web demo using **Dash**
- CPU-friendly (no GPU required)

---

## ğŸ§© Model Architecture

### Encoder
- Embedding layer
- Bidirectional GRU
- Hidden state projection

### Decoder
- Embedding layer
- Additive Attention
- GRU
- Linear output layer over target vocabulary

### Attention
- Additive (Bahdanau) Attention
- Computes alignment between decoder hidden state and encoder outputs

---

## ğŸ“‚ Project Structure

```
A3-Machine-Translation/
â”‚
â”œâ”€â”€ app.py                  # Dash web application
â”œâ”€â”€ mt_attention_ckpt.pt    # Trained model checkpoint
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Project documentation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # Raw OpenSubtitles data
â”‚   â””â”€â”€ processed/          # train / valid / test TSV files
â”‚
â”œâ”€â”€ st126130_notebook_A3.ipynb  # Training & experiments notebook
```

---

## âš™ï¸ Installation

### 1. Create virtual environment (optional)

```bash
python -m venv vn_A3
source vn_A3/bin/activate        # macOS / Linux
vn_A3\Scripts\activate           # Windows
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### Required Packages
- torch
- numpy
- pythainlp
- dash
- dash-bootstrap-components

---

## â–¶ï¸ Running the Web Application

Start the Dash app:

```bash
python app.py
```

You should see:

```
Dash is running on http://127.0.0.1:8050/
```

Open your browser at:

ğŸ‘‰ **http://127.0.0.1:8050/**

---

## ğŸŒ How to Use the Web Interface

1. Enter a **Thai sentence** in the text area  
   Example:
   ```
   à¸‰à¸±à¸™à¸£à¸±à¸à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸—à¸¢
   ```

2. Click the **Translate** button

3. The translated **English sentence** will appear below

---

### Web-based Machine Translation Demo (Dash)

The following screenshot shows the deployed Dash web application for Thai â†’ English machine translation using a Seq2Seq model with Additive Attention.

![Dash Web Demo â€“ Thai to English Translation](demo.png)


## ğŸ“¦ Model Checkpoint

The checkpoint file `mt_attention_ckpt.pt` contains:
- Encoderâ€“Decoder parameters
- Additive and General attention state dictionaries
- Vocabulary mappings (stoi / itos)
- Model configuration

---

## ğŸ“ Assignment Tasks Covered

- Task 1: Language Pair Preparation
- Task 2: Tokenization & Vocabulary
- Task 3: Seq2Seq with Attention
- Task 4: Web-based Inference Demo

---

## ğŸ‘¤ Author

- Student ID: **st126130**
- Course: Natural Language Processing

---

## ğŸ“œ License

Educational use only.
